{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import phate\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_feather('sample_var_phenos_all_v2.feather').set_index('sampleID').drop(columns=[\n",
    "                                                                                                'CHIP_Gene', \n",
    "                                                                                                'AD', \n",
    "                                                                                                'AgeAt_All_Pneumonia', \n",
    "                                                                                                'AF', \n",
    "                                                                                                'Incd_Hypertension', \n",
    "                                                                                                'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex_numeric 0\n",
      "age 0\n",
      "SmokingStatus 0\n",
      "ever_smoked 0\n",
      "age2 0\n",
      "PC1 53\n",
      "PC2 53\n",
      "PC3 53\n",
      "PC4 53\n",
      "PC5 53\n",
      "PC6 53\n",
      "PC7 53\n",
      "PC8 53\n",
      "PC9 53\n",
      "PC10 53\n",
      "Coronary_Artery_Disease_SOFT 0\n",
      "Prev_Coronary_Artery_Disease_SOFT 1079\n",
      "Incd_Coronary_Artery_Disease_SOFT 2041\n",
      "Coronary_Artery_Disease_SOFT_FollowUp 0\n",
      "Death 0\n",
      "Prev_Death 713\n",
      "Incd_Death 0\n",
      "Death_FollowUp 0\n",
      "Diabetes_All 0\n",
      "Prev_Diabetes_All 605\n",
      "Incd_Diabetes_All 1955\n",
      "Diabetes_All_FollowUp 0\n",
      "Diabetes_Type_1 0\n",
      "Prev_Diabetes_Type_1 82\n",
      "Incd_Diabetes_Type_1 165\n",
      "Diabetes_Type_1_FollowUp 0\n",
      "Diabetes_Type_2 0\n",
      "Prev_Diabetes_Type_2 962\n",
      "Incd_Diabetes_Type_2 865\n",
      "Diabetes_Type_2_FollowUp 0\n",
      "Heart_Failure 19\n",
      "Prev_Heart_Failure 285\n",
      "Incd_Heart_Failure 217\n",
      "Heart_Failure_FollowUp 19\n",
      "Hypercholesterolemia 0\n",
      "Prev_Hypercholesterolemia 1977\n",
      "Incd_Hypercholesterolemia 5537\n",
      "Hypercholesterolemia_FollowUp 0\n",
      "Hypertension 0\n",
      "Prev_Hypertension 2031\n",
      "Hypertension_FollowUp 0\n",
      "hasCHIP 0\n",
      "AML 1\n",
      "Prev_AML 1\n",
      "Incd_AML 21\n",
      "AML_FollowUp 1\n",
      "MPN 1\n",
      "Prev_MPN 1\n",
      "Incd_MPN 37\n",
      "MPN_FollowUp 1\n",
      "Platelet count 1100\n",
      "Platelet crit 1100\n",
      "Mean platelet volume 1100\n",
      "Platelet distribution width 1100\n",
      "All_Pneumonia 1\n",
      "Incd_All_Pneumonia 1\n",
      "All_Pneumonia_FollowUp 1\n",
      "Prev_All_Pneumonia 1\n"
     ]
    }
   ],
   "source": [
    "#Check NAN values in all phenotypes:\n",
    "i = -63\n",
    "for nan  in temp.isna().sum().to_list()[-63:]:\n",
    "    print(temp.columns[i], nan) #nan counts\n",
    "    i += 1\n",
    "    \n",
    "del i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.drop(columns=[\n",
    "    'age',\n",
    "    'age2',\n",
    "    'PC1',\n",
    "    'PC2',\n",
    "    'PC3',\n",
    "    'PC4',\n",
    "    'PC5',\n",
    "    'PC6',\n",
    "    'PC7',\n",
    "    'PC8',\n",
    "    'PC9',\n",
    "    'PC10',\n",
    "    'Prev_Coronary_Artery_Disease_SOFT',\n",
    "    'Incd_Coronary_Artery_Disease_SOFT',\n",
    "    'Coronary_Artery_Disease_SOFT_FollowUp',\n",
    "    'Death',\n",
    "    'Prev_Death',\n",
    "    'Incd_Death',\n",
    "    'Death_FollowUp',\n",
    "    'Diabetes_All',\n",
    "    'Prev_Diabetes_All',\n",
    "    'Incd_Diabetes_All',\n",
    "    'Diabetes_All_FollowUp',\n",
    "    'Prev_Diabetes_Type_1',\n",
    "    'Incd_Diabetes_Type_1',\n",
    "    'Diabetes_Type_1_FollowUp',\n",
    "    'Prev_Diabetes_Type_2',\n",
    "    'Incd_Diabetes_Type_2',\n",
    "    'Diabetes_Type_2_FollowUp',\n",
    "    'Prev_Heart_Failure',\n",
    "    'Incd_Heart_Failure',\n",
    "    'Heart_Failure_FollowUp',\n",
    "    'Prev_Hypercholesterolemia',\n",
    "    'Incd_Hypercholesterolemia',\n",
    "    'Hypercholesterolemia_FollowUp',\n",
    "    'Prev_Hypertension',\n",
    "    'Hypertension_FollowUp',\n",
    "    'Prev_AML',\n",
    "    'Incd_AML',\n",
    "    'AML_FollowUp',\n",
    "    'Prev_MPN',\n",
    "    'Incd_MPN',\n",
    "    'MPN_FollowUp',\n",
    "    'Incd_All_Pneumonia',\n",
    "    'All_Pneumonia_FollowUp',\n",
    "    'Prev_All_Pneumonia',\n",
    "    'Platelet count',\n",
    "    'Platelet crit',\n",
    "    'Mean platelet volume',\n",
    "    'Platelet distribution width']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = temp[[\n",
    "                    'Hypercholesterolemia',\n",
    "                    'Hypertension',\n",
    "                    'hasCHIP',\n",
    "                    'AML',\n",
    "                    'MPN',\n",
    "                    'All_Pneumonia',\n",
    "                    'Sex_numeric',\n",
    "                    'SmokingStatus',\n",
    "                    'ever_smoked',\n",
    "                    'Coronary_Artery_Disease_SOFT',\n",
    "                    'Diabetes_Type_1',\n",
    "                    'Diabetes_Type_2',\n",
    "                    'Heart_Failure']]\n",
    "data = temp.drop(columns=[\n",
    "                            'Hypercholesterolemia',\n",
    "                            'Hypertension',\n",
    "                            'hasCHIP',\n",
    "                            'AML',\n",
    "                            'MPN',\n",
    "                            'All_Pneumonia',\n",
    "                            'Sex_numeric',\n",
    "                            'SmokingStatus',\n",
    "                            'ever_smoked',\n",
    "                            'Coronary_Artery_Disease_SOFT',\n",
    "                            'Diabetes_Type_1',\n",
    "                            'Diabetes_Type_2',\n",
    "                            'Heart_Failure'])\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALISATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA with data normalization\n",
    "#not using phenotypes for my clustering methods, instead using them as labels\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "\n",
    "X_train_scaled = scaler.transform(data)\n",
    "\n",
    "pca_scaled = PCA()\n",
    "\n",
    "X_pca_scaled = pca_scaled.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust number of PCs used in the future analyses according to this graph:\n",
    "plt.plot(np.cumsum(pca_scaled.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot PC0 vs PC1 -- can play with other PCs:\n",
    "for phenotype in phenotypes.columns:\n",
    "    plt.figure()\n",
    "    plt.scatter(X_pca_scaled[:, 0], X_pca_scaled[:, 1], c=phenotypes[phenotype], s=100, alpha=.4) #s = size, alpha = transparency \n",
    "    plt.xlabel(phenotype + \" PCA feature 0\")\n",
    "    plt.ylabel(\"PCA feature 1\")\n",
    "    # Show/save figure as desired.\n",
    "    plt.show()\n",
    "# Can show all four figures at once by calling plt.show() here, outside the loop.\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If necessary, use only a portion of the data:\n",
    "# reduced_pca = np.vstack((X_pca_scaled[phenotypes.hasCHIP == 1], X_pca_scaled[phenotypes.hasCHIP == 0][0:9000,:]))\n",
    "# reduced_pca_notsc = np.vstack((X_pca[phenotypes.hasCHIP == 1], X_pca[phenotypes.hasCHIP == 0][0:9000,:]))\n",
    "#replace data.hasCHIP by phenotype of interest and adjust 9000 to some other number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-SNE:\n",
    "tsne = TSNE(random_state=42, n_components=2, n_jobs=-1)\n",
    "tsne_data = tsne.fit_transform(X_pca_scaled[:, 0:1900])#adjust '1900' according to the # of PCs you are using; use reduced_pca[:, 0:1900] instead if using only a slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phenotype in phenotypes.data:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlim(tsne_data[:, 0].min(), tsne_data[:, 0].max() + 1) #decrease '1' if the graph looks empty\n",
    "    plt.ylim(tsne_data[:, 1].min(), tsne_data[:, 1].max() + 1)\n",
    "\n",
    "    plt.scatter(tsne_data[:, 0], tsne_data[:, 1], c=phenotypes[phenotype]) #s = size, alpha = transparency \n",
    "    plt.xlabel(phenotype + \" t-SNE feature 0\")\n",
    "    plt.ylabel(\"t-SNE feature 1\")\n",
    "    # Show/save figure as desired.\n",
    "    plt.show()\n",
    "# Can show all four figures at once by calling plt.show() here, outside the loop.\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PHATE:\n",
    "phate_op = phate.PHATE(n_pca=1900, n_jobs=-1) #adjust the num of PCs according to the variance covered#T-SNE:\n",
    "tsne = TSNE(random_state=42, n_components=2, n_jobs=-1)\n",
    "tsne_data = tsne.fit_transform(X_pca_scaled[:, 0:1900])#adjust '1900' according to the # of PCs you are using; use reduced_pca[:, 0:1900] instead if using only a slice of the data\n",
    "data_phate = phate_op.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phenotype in phenotypes:\n",
    "    phate.plot.scatter2d(data_phate, c=phenotypes[phenotype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans:\n",
    "kmeans = KMeans(n_jobs=-1) #can play with n_clusters= and max_iter=; default is 8 and 300 respectively\n",
    "kmeans.fit(X_pca_scaled[:, 0:1900]) #adjust 1900 to number of PCs#T-SNE:\n",
    "tsne = TSNE(random_state=42, n_components=2, n_jobs=-1)\n",
    "tsne_data = tsne.fit_transform(X_pca_scaled[:, 0:1900])#adjust '1900' according to the # of PCs you are using; use reduced_pca[:, 0:1900] instead if using only a slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(kmeans.labels_, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agglomerative-Ward\n",
    "agg = AgglomerativeClustering() #can play with (e.g., n_clusters=2); default is 8\n",
    "assignment = agg.fit_predict(X_pca_scaled[:, 0:1900]) #adjust 1900 to number of PCs#T-SNE:\n",
    "tsne = TSNE(random_state=42, n_components=2, n_jobs=-1)\n",
    "tsne_data = tsne.fit_transform(X_pca_scaled[:, 0:1900])#adjust '1900' according to the # of PCs you are using; use reduced_pca[:, 0:1900] instead if using only a slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(assignment, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agglomerative-Complete\n",
    "agg = AgglomerativeClustering(linkage=\"complete\") #can play with (e.g., n_clusters=2); default is 8\n",
    "assignment = agg.fit_predict(X_pca_scaled[:, 0:1900]) #adjust 1900 to number of PCs#T-SNE:\n",
    "tsne = TSNE(random_state=42, n_components=2, n_jobs=-1)\n",
    "tsne_data = tsne.fit_transform(X_pca_scaled[:, 0:1900])#adjust '1900' according to the # of PCs you are using; use reduced_pca[:, 0:1900] instead if using only a slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(assignment, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agglomerative-Average\n",
    "agg = AgglomerativeClustering(linkage=\"average\") #can play with (e.g., n_clusters=2); default is 8\n",
    "assignment = agg.fit_predict(X_pca_scaled[:, 0:1900]) #adjust 1900 to number of PCs#T-SNE:\n",
    "tsne = TSNE(random_state=42, n_components=2, n_jobs=-1)\n",
    "tsne_data = tsne.fit_transform(X_pca_scaled[:, 0:1900])#adjust '1900' according to the # of PCs you are using; use reduced_pca[:, 0:1900] instead if using only a slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(assignment, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN:\n",
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X_pca_scaled[:, 0:1900]) #adjust 1900 to number of PCs#T-SNE:\n",
    "tsne = TSNE(random_state=42, n_components=2, n_jobs=-1)\n",
    "tsne_data = tsne.fit_transform(X_pca_scaled[:, 0:1900])#adjust '1900' according to the # of PCs you are using; use reduced_pca[:, 0:1900] instead if using only a slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(clusters, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPARE CLUSTERING ALGOS:\n",
    "fig, axes = plt.subplots(1, 6, figsize=(15, 3),\n",
    "                         subplot_kw={'xticks': (), 'yticks': ()})\n",
    "\n",
    "# make a list of algorithms to use\n",
    "algorithms = [KMeans(n_jobs=-1, n_clusters=2), \n",
    "              AgglomerativeClustering(n_clusters=2), \n",
    "              AgglomerativeClustering(n_clusters=2, linkage=\"complete\"),\n",
    "              AgglomerativeClustering(n_clusters=2, linkage=\"average\"),\n",
    "              DBSCAN()]\n",
    "\n",
    "# create a random cluster assignment for reference\n",
    "random_state = np.random.RandomState(seed=0)\n",
    "random_clusters = random_state.randint(low=0, high=2, size=len(data))\n",
    "\n",
    "# plot random assignment\n",
    "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters,\n",
    "                cmap=mglearn.cm3, s=60)\n",
    "axes[0].set_title(\"Random assignment - ARI: {:.2f}\".format(\n",
    "        adjusted_rand_score(y, random_clusters)))\n",
    "\n",
    "for ax, algorithm in zip(axes[1:], algorithms):\n",
    "    # plot the cluster assignments and cluster centers\n",
    "    clusters = algorithm.fit_predict(X_scaled)\n",
    "    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, s=60)\n",
    "    ax.set_title(\"{} - ARI: {:.2f}\".format(algorithm.__class__.__name__,\n",
    "                                           adjusted_rand_score(y, clusters)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
